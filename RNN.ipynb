{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168e0a8f",
   "metadata": {},
   "source": [
    "## Construct a single layer RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c92c966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2249,  0.1533, -0.0034],\n",
      "         [ 0.3328, -0.1285, -0.3007]]], grad_fn=<TransposeBackward1>) torch.Size([1, 2, 3])\n",
      "tensor([[[ 0.3328, -0.1285, -0.3007]]], grad_fn=<StackBackward0>) torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "single_rnn = nn.RNN(4, 3, 1, batch_first=True) #input_size * hidden_size * num_layers\n",
    "data = torch.randn(1, 2, 4) # batch_size * sequence_length * input_features\n",
    "output, h_n = single_rnn(data)\n",
    "print(output, output.shape) # bs * sl * (D*out_features) if bidirectional is True, D=2, otherwise D=1\n",
    "print(h_n, h_n.shape) # bs * (D*num_layers) * h_out, the final hidden state for each element in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c00c81",
   "metadata": {},
   "source": [
    "## Construct a bidirectional and single layer RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3483d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0799, -0.2464, -0.3475, -0.4973, -0.0137,  0.0037],\n",
      "         [-0.4458, -0.0231, -0.1119, -0.3422,  0.0224, -0.0042]]],\n",
      "       grad_fn=<TransposeBackward1>) torch.Size([1, 2, 6])\n",
      "tensor([[[-0.4458, -0.0231, -0.1119]],\n",
      "\n",
      "        [[-0.4973, -0.0137,  0.0037]]], grad_fn=<StackBackward0>) torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "bidirectional_rnn = nn.RNN(4, 3, 1, batch_first=True, bidirectional=True) #input_size * hidden_size * num_layers\n",
    "bi_output, bi_h_n = bidirectional_rnn(data)\n",
    "print(bi_output, bi_output.shape)\n",
    "print(bi_h_n, bi_h_n.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bbb1f9",
   "metadata": {},
   "source": [
    "## Verify PyTorch RNN API by writing code according to math \n",
    "Reference: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
    "\n",
    "Applies a multi-layer Elman RNN with $\\tanh$ or $\\text{ReLU}$ non-linearity to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
    "$$\n",
    "h_t = \\tanh(W_{ih}^Tx_t+b_{ih}+W_{hh}^Th_{t-1}+b_{hh})\n",
    "$$\n",
    "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $0$.\n",
    "\n",
    "`batch_first` â€“ If `True`, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). **Note that this does not apply to hidden or cell states.** See the Inputs/Outputs sections below for details. Default: `False`\n",
    "\n",
    "h_0: tensor of shape ($D$ * $\\text{num_layers}$, $H_{out}$) for unbatched input or ($D * \\text{num_layers}, N, H_{out}$) containing the initial hidden state for the input sequence batch. Defaults to zeros if not provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f093229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7509,  0.0179,  0.3901],\n",
      "         [-0.3166, -0.2233, -0.1727],\n",
      "         [-0.2619, -0.0492, -0.1413],\n",
      "         [ 0.1561,  0.3625, -0.1462]],\n",
      "\n",
      "        [[-0.7074,  0.4189,  0.6072],\n",
      "         [-0.5832, -0.2940,  0.1098],\n",
      "         [-0.7248,  0.0336,  0.4950],\n",
      "         [-0.4684, -0.1603, -0.0052]]], grad_fn=<TransposeBackward1>) torch.Size([2, 4, 3])\n",
      "tensor([[[ 0.1561,  0.3625, -0.1462],\n",
      "         [-0.4684, -0.1603, -0.0052]]], grad_fn=<StackBackward0>) torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "T = 4 # sequence length\n",
    "input_size, hidden_size = 2, 3\n",
    "num_layers = 1\n",
    "D = 1\n",
    "data = torch.randn(batch_size, T, input_size) # bs * sl * num_in_feat\n",
    "h_prev = torch.zeros(D*num_layers, batch_size, hidden_size) # the initial hidden features, (D*num_layers) * bs * hidden_size\n",
    "\n",
    "rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "rnn_output, final_state = rnn(data, h_prev)\n",
    "print(rnn_output, rnn_output.shape) # bs * sl * h_out\n",
    "print(final_state, final_state.shape) # (D*num_layers) * N * h_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153bdde",
   "metadata": {},
   "source": [
    "### Take a look at the weights of a RNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e24f9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([3, 2])\n",
      "weight_hh_l0 torch.Size([3, 3])\n",
      "bias_ih_l0 torch.Size([3])\n",
      "bias_hh_l0 torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for n,p in rnn.named_parameters():\n",
    "    print(n,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "310ab5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(data, weight_ih, weight_hh, bias_ih, bias_hh, h_prev):\n",
    "    bs, T, input_size = data.shape\n",
    "    h_dim = weight_ih.shape[0]\n",
    "#     h_out = torch.empty(bs, T, h_dim) # initialize an output matrix\n",
    "    h_out = torch.empty(0)\n",
    "    h_prev = h_prev.permute(1,-1,0) # output: bs * h_size * (D*num_layers)\n",
    "    for t in range(T):\n",
    "        x = data[:,t,:].unsqueeze(2) # bs * num_feat * 1\n",
    "        batch_w_ih = weight_ih.tile(bs, 1, 1) # bs * h_size * in_size\n",
    "        batch_w_hh = weight_hh.tile(bs, 1, 1) # bs * h_size * h_size\n",
    "        part1 = torch.bmm(batch_w_ih, x) + bias_ih.unsqueeze(-1) # the size of the first term: bs*h_size*1, second term: h_size*1\n",
    "        part2 = torch.bmm(batch_w_hh, h_prev) + bias_hh.unsqueeze(-1)# the size of the first term: bs*h_size*1, second term: h_size*1\n",
    "        h_prev = torch.tanh(part1 + part2) # bs * h_size * 1\n",
    "        \n",
    "        h_out = torch.cat([h_out,h_prev],dim=2) # concat h_out and h_prev on the dimension of time\n",
    "        \n",
    "    return h_out.permute(0,2,1), h_prev.permute(2,0,1) # permute to align with the shapes of the PyTorch APIs' output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5a558d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7509,  0.0179,  0.3901],\n",
      "         [-0.3166, -0.2233, -0.1727],\n",
      "         [-0.2619, -0.0492, -0.1413],\n",
      "         [ 0.1561,  0.3625, -0.1462]],\n",
      "\n",
      "        [[-0.7074,  0.4189,  0.6072],\n",
      "         [-0.5832, -0.2940,  0.1098],\n",
      "         [-0.7248,  0.0336,  0.4950],\n",
      "         [-0.4684, -0.1603, -0.0052]]], grad_fn=<PermuteBackward0>) torch.Size([2, 4, 3])\n",
      "tensor([[[ 0.1561,  0.3625, -0.1462],\n",
      "         [-0.4684, -0.1603, -0.0052]]], grad_fn=<PermuteBackward0>) torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "custom_rnn_output, custom_final_state = rnn_forward(data, rnn.weight_ih_l0, rnn.weight_hh_l0, rnn.bias_ih_l0, rnn.bias_hh_l0, h_prev)\n",
    "print(custom_rnn_output, custon_rnn_output.shape)\n",
    "print(custom_final_state, custom_final_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f7c64355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(custom_rnn_output,rnn_output), torch.allclose(custom_final_state,final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d9528ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_rnn_forward(data, weight_ih, weight_hh, bias_ih, bias_hh, h_prev,\\\n",
    "                             weight_ih_reverse, weight_hh_reverse, bias_ih_reverse, bias_hh_reverse, h_prev_reverse):\n",
    "    bs, T, input_size = data.shape\n",
    "    h_dim = weight_ih.shape[0]\n",
    "    forward_output, f_final_state = rnn_forward(data, weight_ih, weight_hh, bias_ih, bias_hh, h_prev)\n",
    "    backward_output, b_final_state = rnn_forward(torch.flip(data,dims=(1,)), weight_ih_reverse, weight_hh_reverse, \\\n",
    "                                  bias_ih_reverse, bias_hh_reverse, h_prev_reverse) # reverse the data on time dimension\n",
    "    \n",
    "    output = torch.concat([forward_output,backward_output.flip(dims=(1,))], dim=-1) # reverse again\n",
    "    final_output = torch.concat([f_final_state, b_final_state], dim=0)\n",
    "    return output, final_output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "73deefdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1752,  0.0359, -0.9121, -0.7831, -0.9604, -0.4477],\n",
      "         [-0.0909,  0.6418, -0.2060,  0.3008, -0.7607, -0.0813],\n",
      "         [ 0.0593,  0.5991, -0.3838, -0.2978, -0.6920, -0.6060],\n",
      "         [ 0.1246,  0.7805, -0.6746, -0.8776, -0.9304,  0.3111]],\n",
      "\n",
      "        [[-0.2166, -0.5227, -0.6141, -0.9348, -0.9833, -0.7267],\n",
      "         [-0.0757,  0.2857, -0.2566, -0.0837, -0.7599, -0.3712],\n",
      "         [-0.5078, -0.1643, -0.4274, -0.7758, -0.7244, -0.4726],\n",
      "         [ 0.2099,  0.5098, -0.3588, -0.6636, -0.2914,  0.6622]]],\n",
      "       grad_fn=<TransposeBackward1>) torch.Size([2, 4, 6])\n",
      "tensor([[[ 0.1246,  0.7805, -0.6746],\n",
      "         [ 0.2099,  0.5098, -0.3588]],\n",
      "\n",
      "        [[-0.7831, -0.9604, -0.4477],\n",
      "         [-0.9348, -0.9833, -0.7267]]], grad_fn=<StackBackward0>) torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "bi_rnn = nn.RNN(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "bi_h_prev = torch.randn(2,batch_size,hidden_size)\n",
    "bi_rnn_pytorch_api_output, bi_rnn_pytorch_api_final_state = bi_rnn(data,bi_h_prev)\n",
    "print(bi_rnn_pytorch_api_output, bi_rnn_pytorch_api_output.shape)\n",
    "print(bi_rnn_pytorch_api_final_state, bi_rnn_pytorch_api_final_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d2730c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([3, 2])\n",
      "weight_hh_l0 torch.Size([3, 3])\n",
      "bias_ih_l0 torch.Size([3])\n",
      "bias_hh_l0 torch.Size([3])\n",
      "weight_ih_l0_reverse torch.Size([3, 2])\n",
      "weight_hh_l0_reverse torch.Size([3, 3])\n",
      "bias_ih_l0_reverse torch.Size([3])\n",
      "bias_hh_l0_reverse torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for n,p in bi_rnn.named_parameters():\n",
    "    print(n,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e8c71789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "custom_bi_rnn_output, custom_bi_rnn_final_state = bidirectional_rnn_forward(data,\\\n",
    "                                                                            bi_rnn.weight_ih_l0, \\\n",
    "                                                                            bi_rnn.weight_hh_l0, \\\n",
    "                                                                            bi_rnn.bias_ih_l0, \\\n",
    "                                                                            bi_rnn.bias_hh_l0, \\\n",
    "                                                                            bi_h_prev[0].unsqueeze(0),\\\n",
    "                                                                            bi_rnn.weight_ih_l0_reverse,\\\n",
    "                                                                            bi_rnn.weight_hh_l0_reverse,\\\n",
    "                                                                            bi_rnn.bias_ih_l0_reverse,\\\n",
    "                                                                            bi_rnn.bias_hh_l0_reverse,\\\n",
    "                                                                            bi_h_prev[1].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "dbe4aa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1752,  0.0359, -0.9121, -0.7831, -0.9604, -0.4477],\n",
      "         [-0.0909,  0.6418, -0.2060,  0.3008, -0.7607, -0.0813],\n",
      "         [ 0.0593,  0.5991, -0.3838, -0.2978, -0.6920, -0.6060],\n",
      "         [ 0.1246,  0.7805, -0.6746, -0.8776, -0.9304,  0.3111]],\n",
      "\n",
      "        [[-0.2166, -0.5227, -0.6141, -0.9348, -0.9833, -0.7267],\n",
      "         [-0.0757,  0.2857, -0.2566, -0.0837, -0.7599, -0.3712],\n",
      "         [-0.5078, -0.1643, -0.4274, -0.7758, -0.7244, -0.4726],\n",
      "         [ 0.2099,  0.5098, -0.3588, -0.6636, -0.2914,  0.6622]]],\n",
      "       grad_fn=<CatBackward0>) torch.Size([2, 4, 6])\n",
      "tensor([[[ 0.1246,  0.7805, -0.6746],\n",
      "         [ 0.2099,  0.5098, -0.3588]],\n",
      "\n",
      "        [[-0.7831, -0.9604, -0.4477],\n",
      "         [-0.9348, -0.9833, -0.7267]]], grad_fn=<CatBackward0>) torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(custom_bi_rnn_output,custom_bi_rnn_output.shape)\n",
    "print(custom_bi_rnn_final_state,custom_bi_rnn_final_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "06982aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(custom_bi_rnn_output, bi_rnn_pytorch_api_output), torch.allclose(custom_bi_rnn_final_state, bi_rnn_pytorch_api_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0cbac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
